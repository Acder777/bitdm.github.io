---
layout: page
mathjax: true
permalink: /2018/projects/p10/midterm/
---

## 项目进展报告

### 数据获取及预处理

> 描述项目中使用的数据来源，数据的规模等情况
> 数据是否需要预处理

  数据来自于PDTB2.0(Penn Discourse Treebank)数据集，该数据是华尔街日报新闻标注后的文本语料。其中包含2163个文本文件，共计26MB大小。涉及到18459个显式关系样本和16053个隐式关系样本，624个显隐式兼具的关系样本，5210个实体关系样本，254个没有关系的样本。
624 Alternative Lexicalizations
5210 Entity Relations
254 No Relations
  原数据是按新闻语句划分成各个文件的，所以需要将该数据集中需要的信息抽取并汇总到一个文件中。主要是将其中的论元1、论元2，以及篇章关系信息抽取出来。在实际情况中，有一些错误数据是无法解析的，需要去除这部分样本。另外，对于包含多个关系的样本需要将其拆分成多个单个关系的样本。

### 数据分析与可视化

> 描述对数据进行探索性分析的结果，采用可视化的技术呈现

  原数据是文本数据，每个句子的长度都不一致。其中，对于论元1句子平均长度是12.8个词，其众数是14个词；对于论元2句子平均长度是13.2个词，其众数是15个词。论元1的取值共有177种可能，而论元2的取值共有388种可能，后者远超过前者。
  将每个句子的论元1和论元2的这些特征信息作为X属性，将其篇章关系作为Y属性，利用PCA降维，绘制三维散点图。
  将每个句子的句子向量作为X属性，将其篇章关系作为Y属性，利用PCA降维，绘制三维散点图。
  上述两种散点图难以将样本分隔开，各类数据混杂在一起。

### 模型选取

> 选择了哪些数据挖掘方法对数据进行分析与挖掘，及选择的理由

  使用LSTM神经网络模型来处理该分类问题。原任务是个4分类问题，由于各个类别的比例很不平衡，导致多分类的效果比较差。故而采用多个二分类来模拟多分类，其中每个二分类都使用平衡样本来训练(即正负样本数据量一致)。具体模型描述如下：
  首先利用预先训练好的词向量来构建每个论元的表示向量，这里主要采用双向单层的LSTM模型来产生每个论元的表示。然后将论元1和论元2的表示拼接产生新的向量，最后通过两层全连接神经网络来预测最终的类别。
  选用多个二分类来模拟多分类的好处如前面所言，能应对样本不平衡的问题，能提高模型预测的精度。
  选用BiLSTM来生成论元表示的原因在于该模型能很好存储记忆序列信息，而句子正是一种基于序列表示的信息。

### 挖掘实验的结果

> 进行数据挖掘后得到的结果

  该模型对各个二分类准确率都达到0.6以上，F1值则区别较大。其中样本数量较多的类别F1值较高，而样本数量较少的类别F1值偏低。总的来说，因为数据样本较少，对于神经网络模型而言大数据是保障准确率的一个重要因素。

### 存在的问题

> 到目前为止，遇到哪些问题，及解决方法或思路

  如上述所言，数据样本较少导致准确度不高。可以自己额外在网络上爬取一些显式关系的数据，将其加入模型来训练。另外，可以考虑加入世界知识，这对于篇章分析任务而言很重要。因为人在分析篇章关系的时候主要就是利用了很多额外的世界知识，从而能精准判别。借鉴人的思考方式，将知识融入模型应该也能提升精度。

### 下一步工作

> 准备如何完成后续的工作

  针对上述两个问题加以完善：1、额外扩充训练样本；2、融入世界知识
