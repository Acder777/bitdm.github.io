---
layout: page
mathjax: true
permalink: /2018/projects/p04/midterm/
---

## 项目进展报告

### 数据获取及预处理

> 

在新浪微博平台爬取200个用户在近一年内的微博数据，并筛选出一年内发微博数大于100条的用户，这样获得的数据更有利于属性的分析。



> (1)对爬取得数据进行用户信息提取，提取得到用户id，用户名，以及用户在一年内发的微博内容和时间等；(2)文本分词，针对获得的数据提取出的信息提取关键词，以便于进一步的处理。

### 数据分析与可视化

> 爬取到的微博数据包含微博地址，发布时间，微博内容，点赞数目，评论数目，转发数目等。并且面对这样一个问题：在微博上大部分内容是转发得到的，因此爬取到的内容大都包含链接，所以数据分析十分复杂，目前正处于数据分析实现中。

### 模型选取

> 对于模型的选取，目前阶段考虑两个模型：BTM和LDA。前者直接对语料库中的所有词对中词的生成过程进行建模，并不是直接对文档进行建模。这样的特征比较契合微博短文本的处理。另外，由于现在微博也支持长文本，所以后者也会有一定的效用，LDA是一种无监督学习的算法，在训练的时候仅仅需要文档集并指定主题数量即可。对于大量的文本处理效果会很方便。未来的工作打算在这两个模型中进行选取。

### 挖掘实验的结果

> 目前实验还没有做完，因此最终的实验结果将在最终的报告中进行展示。

### 存在的问题

> (1)在数据获取阶段：由于新浪微博是反爬取的，因此在数据获取过程中遇到很多阻碍。最后采取的方法是采用代理IP的方式，并且要设置一定的时间间隔，然后逐个ID进行获取数据。


(2)在数据预处理阶段：由于数据获取的格式是文本类型的，数据格式不是特别统一，这对分词有一定的影响，所以首先要对一些不规范的文本进行去除。


(3)获取到的数据质量不佳，很有可能影响到后续的工作。这将直接影响到实验结果的可信度。

### 下一步工作

> 下一步将按照小组既定的计划进行相关的实验，形成最终的报告。
